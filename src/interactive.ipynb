{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe38cb6-9a05-4b82-8f75-78d207f639a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b116d5-ec5e-4459-b737-ed7244d85790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import templates\n",
    "import convert\n",
    "\n",
    "from _info import DATA_STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893b6017-c6e5-4a6e-b82a-630534e9e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filing:\n",
    "    # Class to take care of filing each dataframe + additional functionality later on\n",
    "    def __init__(self, season: str):\n",
    "\n",
    "        self.season = season\n",
    "        self.data_dir = os.getcwd().replace('src', 'data')\n",
    "        self.season_dir = os.path.join(self.data_dir, season)\n",
    "        self.boxscores_dir = os.path.join(self.season_dir, 'boxscores')\n",
    "\n",
    "        # Check to make sure if directories exist, if not create them\n",
    "        for directory in (self.data_dir, self.season_dir, self.boxscores_dir):\n",
    "            if not os.path.exists(directory):\n",
    "                os.mkdir(directory)\n",
    "\n",
    "\n",
    "    def save_boxscore(self, df: pd.DataFrame, weeknum: int) -> None:\n",
    "        \"\"\"\n",
    "        Saves boxscore as csv (later on can configure different formats)\n",
    "        Saves in form of away-home-week#.csv\n",
    "        \"\"\"\n",
    "        teams = sorted(list(df['team'].drop_duplicates()))\n",
    "        filename = f'{\"-\".join(teams)}-week{weeknum}.csv'\n",
    "        \n",
    "        fpath = os.path.join(self.boxscores_dir, filename)\n",
    "        df.to_csv(fpath, index=False)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2186d7-1656-4dfc-a0db-19e822aeb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxscoreScraper:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.year: int = int(kwargs.get('year', 2022))\n",
    "        self.season: str = f'{self.year}-{self.year+1}'\n",
    "\n",
    "        # Initialize filing object\n",
    "        self.filing = Filing(self.season)\n",
    "        \n",
    "        # Going to start with just regular season\n",
    "        self.week_pages = {\n",
    "            week: templates.week_url(self.year, week)\n",
    "            for week in range(1,19)\n",
    "        }\n",
    "\n",
    "        self.data_stats = DATA_STATS\n",
    "\n",
    "    def get_week_boxscores(self, week: int, url: str):\n",
    "        \"\"\"\n",
    "        Returns every boxscore for given week and saves it to directory\n",
    "        \"\"\"\n",
    "\n",
    "        root_url: str = 'https://www.pro-football-reference.com/'\n",
    "        \n",
    "        # Seems a little redundant having self.week_pages rn\n",
    "        week_games_soup = BeautifulSoup(\n",
    "            requests.get(url).text,\n",
    "            'html.parser'\n",
    "        )\n",
    "\n",
    "\n",
    "        for game in week_games_soup.find_all('div', class_='game_summary expanded nohover'):\n",
    "            \n",
    "            game_url: str = f\"{root_url}{game.find_all('td', class_='right gamelink')[0].find('a')['href']}\"\n",
    "            game_soup = BeautifulSoup(\n",
    "                requests.get(game_url).text,\n",
    "                'html.parser'\n",
    "            )\n",
    "\n",
    "            stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "    \n",
    "            # Different for names because th not td\n",
    "            names = [\n",
    "                tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "                if tag.get_text() != 'Player'\n",
    "            ]\n",
    "            \n",
    "            table_data = {\n",
    "                stat: [td.get_text() for td in stat_table.find_all('td', attrs={'data-stat': stat})]\n",
    "                for stat in DATA_STATS[1:]\n",
    "            }\n",
    "            \n",
    "            \n",
    "            # Will do rest of cleaning later on, just wanted to not have any NA values in saved files and have standardized team names\n",
    "            fix_rating = lambda rating_str: float(rating_str) if len(rating_str) else 0.0\n",
    "            table_data['pass_rating'] = [fix_rating(rating) for rating in table_data['pass_rating']]\n",
    "            table_data['team'] = [convert.initials(team) for team in table_data['team']]\n",
    "            \n",
    "            df = pd.DataFrame(data={**{'name': names}, **table_data})\n",
    "            self.filing.save_boxscore(df, week)\n",
    "        \n",
    "\n",
    "        return\n",
    "\n",
    "    def get_season_boxscores(self) -> None:\n",
    "        \"\"\"\n",
    "        Iterates through every boxscore for every game of every week\n",
    "        Saves to data directory\n",
    "        \"\"\"\n",
    "\n",
    "        for weeknum, url in tqdm(self.week_pages.items()):\n",
    "            print(f'Scraping boxscores for Week {weeknum}')\n",
    "            self.get_week_boxscores(weeknum, url)\n",
    "            # Need to sleep for 60 seconds so requests do not get blocked\n",
    "            time.sleep(60)\n",
    "            print(f'Succesfully scraped boxscores for Week {weeknum}\\n')\n",
    "        \n",
    "        \n",
    "        return\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c93563-0ad5-47e6-8cc8-829ad39c1467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb19ee76877344c49b1887684f49ee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping boxscores for Week 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'week' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scraper \u001b[38;5;241m=\u001b[39m BoxscoreScraper()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_season_boxscores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 74\u001b[0m, in \u001b[0;36mBoxscoreScraper.get_season_boxscores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weeknum, url \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweek_pages\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping boxscores for Week \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweeknum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_week_boxscores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweeknum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# Need to sleep for 60 seconds so requests do not get blocked\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m, in \u001b[0;36mBoxscoreScraper.get_week_boxscores\u001b[0;34m(self, week, url)\u001b[0m\n\u001b[1;32m     58\u001b[0m     table_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [convert\u001b[38;5;241m.\u001b[39minitials(team) \u001b[38;5;28;01mfor\u001b[39;00m team \u001b[38;5;129;01min\u001b[39;00m table_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     60\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: names}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtable_data})\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_boxscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mFiling.save_boxscore\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mSaves boxscore as csv (later on can configure different formats)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mSaves in form of away-home-week#.csv\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m teams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdrop_duplicates()))\n\u001b[0;32m---> 22\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(teams)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-week\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mweek\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboxscores_dir, filename)\n\u001b[1;32m     25\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(fpath, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'week' is not defined"
     ]
    }
   ],
   "source": [
    "scraper = BoxscoreScraper()\n",
    "scraper.get_season_boxscores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46405f5-9f97-4a21-b817-c3fda9f29a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week_games_soup = BeautifulSoup(\n",
    "#     requests.get('https://www.pro-football-reference.com/years/2022/week_1.htm').text,\n",
    "#     'html.parser'\n",
    "# )\n",
    "\n",
    "# root_url: str = 'https://www.pro-football-reference.com/'\n",
    "\n",
    "# for game in week_games_soup.find_all('div', class_='game_summary expanded nohover')[:1]:\n",
    "#     game_url: str = f\"{root_url}{game.find_all('td', class_='right gamelink')[0].find('a')['href']}\"\n",
    "#     game_soup = BeautifulSoup(\n",
    "#         requests.get(game_url).text,\n",
    "#         'html.parser'\n",
    "#     )\n",
    "\n",
    "#     stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "\n",
    "#     # Different for names because th not td\n",
    "#     names = [\n",
    "#         tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "#         if tag.get_text() != 'Player'\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a6573-6d9d-4237-9471-5b6001de0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get jailed for an hour if >= 20 requests / minute\n",
    "\n",
    "# single_url = 'https://www.pro-football-reference.com/boxscores/202209080ram.htm'\n",
    "\n",
    "# game_soup = BeautifulSoup(\n",
    "#     # requests.get(game_url).text,\n",
    "#     requests.get(single_url).text,\n",
    "#     'html.parser'\n",
    "# )\n",
    "\n",
    "# stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "\n",
    "# # Different for names because th not td\n",
    "# names = [\n",
    "#     tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "#     if tag.get_text() != 'Player'\n",
    "# ]\n",
    "\n",
    "# table_data = {\n",
    "#     stat: [td.get_text() for td in stat_table.find_all('td', attrs={'data-stat': stat})]\n",
    "#     for stat in DATA_STATS[1:]\n",
    "# }\n",
    "\n",
    "\n",
    "# # Will do rest of cleaning later on, just wanted to not have any NA values\n",
    "# fix_rating = lambda rating_str: float(rating_str) if len(rating_str) else 0.0\n",
    "# table_data['pass_rating'] = [fix_rating(rating) for rating in table_data['pass_rating']]\n",
    "\n",
    "# df = pd.DataFrame(data={**{'name': names}, **table_data})\n",
    "# teams = tuple(sorted(list(df['team'].drop_duplicates())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6924a4-547f-4d97-87d1-ada3a44b5177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2390b8-2987-4799-b1f5-44b31f413f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc13c7a-a90a-4784-8262-ed7191809bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fff399-1233-4175-8f19-3c9a3b6a43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_table.find_all('td', attrs={'data-stat': 'team'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454b4d9-0a4d-4fe4-b367-8b262d782d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# table_data_with_names = {\n",
    "#     **{'name': names},\n",
    "#     **table_data\n",
    "# }\n",
    "\n",
    "# pd.DataFrame(data = table_data_with_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae70c8e-b4e7-4b48-aa45-6ba0657ac18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
