{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe38cb6-9a05-4b82-8f75-78d207f639a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b116d5-ec5e-4459-b737-ed7244d85790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import templates\n",
    "import convert\n",
    "\n",
    "from _info import DATA_STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893b6017-c6e5-4a6e-b82a-630534e9e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filing:\n",
    "    # Class to take care of filing each dataframe + additional functionality later on\n",
    "    def __init__(self, season: str):\n",
    "\n",
    "        self.season = season\n",
    "        self.data_dir = os.getcwd().replace('src', 'data')\n",
    "        self.season_dir = os.path.join(self.data_dir, season)\n",
    "        self.boxscores_dir = os.path.join(self.season_dir, 'boxscores')\n",
    "\n",
    "        # Check to make sure if directories exist\n",
    "        for directory in (self.data_dir, self.season_dir, self.boxscores_dir):\n",
    "            if not os.path.exists(directory):\n",
    "                os.mkdir(directory)\n",
    "\n",
    "\n",
    "    def save_boxscore(self, filename: str, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Saves boxscore as csv (later on can configure different formats)\n",
    "        Saves in form of away-home-week#.csv\n",
    "        \"\"\"\n",
    "        fpath: str = os.path.join(self.boxscores_dir, filename)\n",
    "        df.to_csv(fpath, index=False)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2186d7-1656-4dfc-a0db-19e822aeb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxscoreScraper:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.year: int = int(kwargs.get('year', 2022))\n",
    "        self.season: str = f'{self.year}-{self.year+1}'\n",
    "\n",
    "        # Initialize filing object\n",
    "        self.filing = Filing(self.season)\n",
    "        \n",
    "        # Going to start with just regular season\n",
    "        self.week_pages = {\n",
    "            week: templates.week_url(self.year, week)\n",
    "            for week in range(1,19)\n",
    "        }\n",
    "\n",
    "        self.data_stats = DATA_STATS\n",
    "\n",
    "    def get_week_boxscores(self, week: int, url: str):\n",
    "        \"\"\"\n",
    "        Returns every boxscore for given week and saves it to directory\n",
    "        \"\"\"\n",
    "\n",
    "        root_url: str = 'https://www.pro-football-reference.com/'\n",
    "        \n",
    "        # Seems a little redundant having self.week_pages rn\n",
    "        week_games_soup = BeautifulSoup(\n",
    "            requests.get(url).text,\n",
    "            'html.parser'\n",
    "        )\n",
    "\n",
    "\n",
    "        for game in week_games_soup.find_all('div', class_='game_summary expanded nohover'):\n",
    "            \n",
    "            game_url: str = f\"{root_url}{game.find_all('td', class_='right gamelink')[0].find('a')['href']}\"\n",
    "            game_soup = BeautifulSoup(\n",
    "                requests.get(game_url).text,\n",
    "                'html.parser'\n",
    "            )\n",
    "\n",
    "            stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "    \n",
    "            # Different for names because th not td\n",
    "            names = [\n",
    "                tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "                if tag.get_text() != 'Player'\n",
    "            ]\n",
    "            \n",
    "            table_data = {\n",
    "                stat: [td.get_text() for td in stat_table.find_all('td', attrs={'data-stat': stat})]\n",
    "                for stat in DATA_STATS[1:]\n",
    "            }\n",
    "            \n",
    "            \n",
    "            # Will do rest of cleaning later on, just wanted to not have any NA values in saved files\n",
    "            fix_rating = lambda rating_str: float(rating_str) if len(rating_str) else 0.0\n",
    "            table_data['pass_rating'] = [fix_rating(rating) for rating in table_data['pass_rating']]\n",
    "            \n",
    "            df = pd.DataFrame(data={**{'name': names}, **table_data})\n",
    "\n",
    "            teams = sorted(list(df['team'].drop_duplicates()))\n",
    "            filename = f'{\"-\".join(teams)}-week{week}'\n",
    "\n",
    "            self.filing.save_boxscore(filename, df)\n",
    "        \n",
    "\n",
    "        return\n",
    "\n",
    "    def get_season_boxscores(self) -> None:\n",
    "        \"\"\"\n",
    "        Iterates through every boxscore for every game of every week\n",
    "        Saves to data directory\n",
    "        \"\"\"\n",
    "\n",
    "        for weeknum, url in tqdm(self.week_pages.items()):\n",
    "            print(f'Scraping boxscores for Week {weeknum}')\n",
    "            self.get_week_boxscores(weeknum, url)\n",
    "            # Need to sleep for 60 seconds so requests do not get blocked\n",
    "            time.sleep(60)\n",
    "            print(f'Succesfully scraped boxscores for Week {weeknum}\\n')\n",
    "        \n",
    "        \n",
    "        return\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c93563-0ad5-47e6-8cc8-829ad39c1467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8605b413be6a4bf396f246cf59a59044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping boxscores for Week 1\n",
      "Succesfully scraped boxscores for Week 1\n",
      "\n",
      "Scraping boxscores for Week 2\n",
      "Succesfully scraped boxscores for Week 2\n",
      "\n",
      "Scraping boxscores for Week 3\n",
      "Succesfully scraped boxscores for Week 3\n",
      "\n",
      "Scraping boxscores for Week 4\n",
      "Succesfully scraped boxscores for Week 4\n",
      "\n",
      "Scraping boxscores for Week 5\n",
      "Succesfully scraped boxscores for Week 5\n",
      "\n",
      "Scraping boxscores for Week 6\n",
      "Succesfully scraped boxscores for Week 6\n",
      "\n",
      "Scraping boxscores for Week 7\n",
      "Succesfully scraped boxscores for Week 7\n",
      "\n",
      "Scraping boxscores for Week 8\n",
      "Succesfully scraped boxscores for Week 8\n",
      "\n",
      "Scraping boxscores for Week 9\n",
      "Succesfully scraped boxscores for Week 9\n",
      "\n",
      "Scraping boxscores for Week 10\n",
      "Succesfully scraped boxscores for Week 10\n",
      "\n",
      "Scraping boxscores for Week 11\n",
      "Succesfully scraped boxscores for Week 11\n",
      "\n",
      "Scraping boxscores for Week 12\n",
      "Succesfully scraped boxscores for Week 12\n",
      "\n",
      "Scraping boxscores for Week 13\n",
      "Succesfully scraped boxscores for Week 13\n",
      "\n",
      "Scraping boxscores for Week 14\n",
      "Succesfully scraped boxscores for Week 14\n",
      "\n",
      "Scraping boxscores for Week 15\n",
      "Succesfully scraped boxscores for Week 15\n",
      "\n",
      "Scraping boxscores for Week 16\n",
      "Succesfully scraped boxscores for Week 16\n",
      "\n",
      "Scraping boxscores for Week 17\n",
      "Succesfully scraped boxscores for Week 17\n",
      "\n",
      "Scraping boxscores for Week 18\n",
      "Succesfully scraped boxscores for Week 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scraper = BoxscoreScraper()\n",
    "scraper.get_season_boxscores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46405f5-9f97-4a21-b817-c3fda9f29a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# week_games_soup = BeautifulSoup(\n",
    "#     requests.get('https://www.pro-football-reference.com/years/2022/week_1.htm').text,\n",
    "#     'html.parser'\n",
    "# )\n",
    "\n",
    "# root_url: str = 'https://www.pro-football-reference.com/'\n",
    "\n",
    "# for game in week_games_soup.find_all('div', class_='game_summary expanded nohover')[:1]:\n",
    "#     game_url: str = f\"{root_url}{game.find_all('td', class_='right gamelink')[0].find('a')['href']}\"\n",
    "#     game_soup = BeautifulSoup(\n",
    "#         requests.get(game_url).text,\n",
    "#         'html.parser'\n",
    "#     )\n",
    "\n",
    "#     stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "\n",
    "#     # Different for names because th not td\n",
    "#     names = [\n",
    "#         tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "#         if tag.get_text() != 'Player'\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a6573-6d9d-4237-9471-5b6001de0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get jailed for an hour if >= 20 requests / minute\n",
    "\n",
    "# single_url = 'https://www.pro-football-reference.com/boxscores/202209080ram.htm'\n",
    "\n",
    "# game_soup = BeautifulSoup(\n",
    "#     # requests.get(game_url).text,\n",
    "#     requests.get(single_url).text,\n",
    "#     'html.parser'\n",
    "# )\n",
    "\n",
    "# stat_table = game_soup.find_all('table', id='player_offense')[0]\n",
    "\n",
    "# # Different for names because th not td\n",
    "# names = [\n",
    "#     tag.get_text() for tag in stat_table.find_all('th', attrs={'data-stat': 'player'})\n",
    "#     if tag.get_text() != 'Player'\n",
    "# ]\n",
    "\n",
    "# table_data = {\n",
    "#     stat: [td.get_text() for td in stat_table.find_all('td', attrs={'data-stat': stat})]\n",
    "#     for stat in DATA_STATS[1:]\n",
    "# }\n",
    "\n",
    "\n",
    "# # Will do rest of cleaning later on, just wanted to not have any NA values\n",
    "# fix_rating = lambda rating_str: float(rating_str) if len(rating_str) else 0.0\n",
    "# table_data['pass_rating'] = [fix_rating(rating) for rating in table_data['pass_rating']]\n",
    "\n",
    "# df = pd.DataFrame(data={**{'name': names}, **table_data})\n",
    "# teams = tuple(sorted(list(df['team'].drop_duplicates())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6924a4-547f-4d97-87d1-ada3a44b5177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2390b8-2987-4799-b1f5-44b31f413f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc13c7a-a90a-4784-8262-ed7191809bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fff399-1233-4175-8f19-3c9a3b6a43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_table.find_all('td', attrs={'data-stat': 'team'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454b4d9-0a4d-4fe4-b367-8b262d782d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# table_data_with_names = {\n",
    "#     **{'name': names},\n",
    "#     **table_data\n",
    "# }\n",
    "\n",
    "# pd.DataFrame(data = table_data_with_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae70c8e-b4e7-4b48-aa45-6ba0657ac18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
